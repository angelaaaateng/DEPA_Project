{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python-GCP Master",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelaaaateng/DEPA_Project/blob/master/Python_GCP_Master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAD0B6WMh0oH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSs56oeUlqFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gcsfs\n",
        "!pip install praw\n",
        "!pip install psaw\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from datetime import date\n",
        "import praw\n",
        "from psaw import PushshiftAPI\n",
        "import gcsfs\n",
        "df_names = pd.read_csv('gs://cryptodb-files/crypto_names.csv')\n",
        "\n",
        "dates_df = pd.DataFrame({'date': pd.date_range(start='1/1/2009', end=date.today()), 'date_id' : range(len(pd.date_range(start='1/1/2009', end=date.today())))})\n",
        "\n",
        "#dates_df.set_index('date_id', inplace = True)\n",
        "\n",
        "dates_df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrOyAuQG6b6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# # Reddit Table\n",
        "# #### Reddit posts from /r/Cryptocurrency from 2017-2019\n",
        "\n",
        "\n",
        "\n",
        "#Connect to reddit API\n",
        "reddit = praw.Reddit(client_id='GjfUHQE8AYnXLg', client_secret='PfbhtsXJGAAUNiEyHPRGPuFJ0ro', user_agent='DEPA_Project')\n",
        "api = PushshiftAPI()\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#Extract all posts to /r/CryptoCurrency from 2017-2019\n",
        "\n",
        "start_epoch=int(dt.datetime(2017, 1, 1).timestamp())\n",
        "end_epoch = int(dt.datetime(2019, 1, 1).timestamp())\n",
        "\n",
        "reddit_data = pd.DataFrame(api.search_submissions(after=start_epoch,\n",
        "                            before=end_epoch,\n",
        "                            subreddit='CryptoCurrency',\n",
        "                            filter=['author', 'title', 'subreddit', 'num_comments', 'created', 'score']))\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#Convert the created_utc column to a date \n",
        "reddit_data['created_utc']=(pd.to_datetime(reddit_data['created_utc'],unit='s'))\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#remove redundant columns\n",
        "reddit_data = reddit_data.drop(['created', 'd_'], axis = 1)\n",
        "\n",
        "\n",
        "# In[11]:\n",
        "\n",
        "\n",
        "#Rename index to post_id\n",
        "reddit_data.index.names = ['post_id']\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#convert created_utc to just a date\n",
        "reddit_data['created_utc'] = reddit_data['created_utc'].dt.date\n",
        "\n",
        "\n",
        "# In[224]:\n",
        "\n",
        "\n",
        "reddit_data['created_utc'] = pd.to_datetime(reddit_data['created_utc'])\n",
        "\n",
        "\n",
        "# In[225]:\n",
        "\n",
        "\n",
        "reddit_data.head()\n",
        "\n",
        "\n",
        "# In[272]:\n",
        "\n",
        "\n",
        "#Add date_id column to reddit_data\n",
        "reddit_data2 = reddit_data.merge(dates_df, how = 'left', left_on = 'created_utc', right_on = 'date')\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#Rename created_utc to date\n",
        "reddit_data2.rename(columns = {'created_utc':'date'}, inplace = True)\n",
        "\n",
        "\n",
        "# In[362]:\n",
        "\n",
        "\n",
        "#Drop date column\n",
        "reddit_data2 = reddit_data2.drop('date', axis = 1)\n",
        "\n",
        "\n",
        "# In[381]:\n",
        "\n",
        "\n",
        "reddit_data2.index.names = ['post_id']\n",
        "\n",
        "\n",
        "# In[385]:\n",
        "\n",
        "\n",
        "reddit_data2.head()\n",
        "\n",
        "\n",
        "# # Create reddit_coins Join Table \n",
        "# #### Matches the reddit posts in reddit_data table to the coins in coins table\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "\n",
        "#Zip the names into tuple of (name, slug, symbol)\n",
        "zipped_names = list(zip(df_names['name'],df_names['slug'],df_names['symbol']))\n",
        "\n",
        "#Create a search list - seperating the three terms with OR operator (|)\n",
        "search_list = []\n",
        "for (name, slug, symbol) in zipped_names:\n",
        "    listt = [name, slug, symbol]\n",
        "    pat = '|'.join(listt)\n",
        "    search_list.append(pat)\n",
        "\n",
        "\n",
        "# In[15]:\n",
        "\n",
        "\n",
        "#Add boolean columns\n",
        "import re\n",
        "dummy_df = pd.DataFrame(dict((name, reddit_data.title.str.contains(name, re.IGNORECASE))\n",
        "                             for name in search_list))\n",
        "\n",
        "\n",
        "# In[17]:\n",
        "\n",
        "\n",
        "#Convert dummy columns into rows with post_id as the index\n",
        "i, j = np.where(dummy_df)\n",
        "\n",
        "coins_mentioned_series = pd.Series(dict(zip(zip(i, j), dummy_df.columns[j])))\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#Create final join table between reddit and coins table. Rename columns of dataframe. \n",
        "coin_reddit_join = pd.DataFrame(coins_mentioned_series).reset_index()\n",
        "coin_reddit_join.columns = ['post_id', 'coin_id', 'coin_name']\n",
        "coin_reddit_join = coin_reddit_join.drop('coin_name', axis = 1)\n",
        "\n",
        "\n",
        "# In[388]:\n",
        "\n",
        "\n",
        "coin_reddit_join2 = coin_reddit_join.set_index(['post_id', 'coin_id'],)\n",
        "\n",
        "\n",
        "# In[389]:\n",
        "\n",
        "\n",
        "coin_reddit_join2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8Kkqatn-QOP",
        "colab_type": "code",
        "outputId": "455ed9a6-e745-42ec-f4de-1b00986810b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# # Pricing Table\n",
        "\n",
        "# In[55]:\n",
        "\n",
        "\n",
        "import requests\n",
        "import datetime\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# In[56]:\n",
        "\n",
        "\n",
        "def daily_price_historical(symbol, comparison_symbol, all_data=True, limit=1, aggregate=1, exchange=''):\n",
        "    url = 'https://min-api.cryptocompare.com/data/histoday?fsym={}&tsym={}&limit={}&aggregate={}'            .format(symbol.upper(), comparison_symbol.upper(), limit, aggregate)\n",
        "    if exchange:\n",
        "        url += '&e={}'.format(exchange)\n",
        "    if all_data:\n",
        "        url += '&allData=true'\n",
        "    page = requests.get(url)\n",
        "    data = page.json()['Data']\n",
        "    df = pd.DataFrame(data)\n",
        "    df['timestamp'] = [datetime.datetime.fromtimestamp(d) for d in df.time]\n",
        "    return df\n",
        "\n",
        "\n",
        "# In[57]:\n",
        "\n",
        "\n",
        "pricing_list = []\n",
        "\n",
        "for symbol in list(df_names['symbol']):\n",
        "# initialise scraper with time interval\n",
        "    try:\n",
        "        df = daily_price_historical(symbol, 'USD')\n",
        "        df['name'] = symbol\n",
        "        pricing_list.append(df)\n",
        "    except:\n",
        "        df2 = pd.DataFrame(columns = df.columns)\n",
        "        pricing_list.append(df2)\n",
        "\n",
        "\n",
        "# In[59]:\n",
        "\n",
        "\n",
        "pricing_df = pd.concat(pricing_list)\n",
        "\n",
        "\n",
        "# In[79]:\n",
        "\n",
        "\n",
        "pricing_df2 = pricing_df.merge(df_names[['symbol', 'coin_id']], how = 'left', left_on = 'name', right_on = 'symbol')\n",
        "pricing_df3 = pricing_df2.drop(['name', 'symbol', 'time'], axis = 1)\n",
        "\n",
        "\n",
        "# In[80]:\n",
        "\n",
        "\n",
        "#Convert to date\n",
        "pricing_df3['timestamp'] = pricing_df3['timestamp'].dt.date\n",
        "\n",
        "\n",
        "# In[233]:\n",
        "\n",
        "\n",
        "#Make it a datetime object \n",
        "pricing_df3['timestamp'] = pd.to_datetime(pricing_df3['timestamp'])\n",
        "\n",
        "\n",
        "# In[275]:\n",
        "\n",
        "\n",
        "#Add date_id column to reddit_data\n",
        "pricing_df4 = pricing_df3.merge(dates_df, how = 'left', left_on = 'timestamp', right_on = 'date')\n",
        "\n",
        "#remove timestamp (replaced with date)\n",
        "pricing_df4 = pricing_df4.drop('timestamp', axis = 1)\n",
        "\n",
        "pricing_df4['date_id'].astype('int')\n",
        "\n",
        "\n",
        "# In[391]:\n",
        "\n",
        "\n",
        "#Drop Redundant date columns\n",
        "pricing_df5 = pricing_df4.drop('date', axis = 1)\n",
        "\n",
        "pricing_df5.set_index(['date_id', 'coin_id'], inplace = True)\n",
        "\n",
        "\n",
        "# In[392]:\n",
        "\n",
        "\n",
        "pricing_df5.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volumefrom</th>\n",
              "      <th>volumeto</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date_id</th>\n",
              "      <th>coin_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3144</th>\n",
              "      <th>0</th>\n",
              "      <td>0.06687</td>\n",
              "      <td>0.4444</td>\n",
              "      <td>0.06687</td>\n",
              "      <td>0.06950</td>\n",
              "      <td>39437.24</td>\n",
              "      <td>2994.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3145</th>\n",
              "      <th>0</th>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.1830</td>\n",
              "      <td>0.06687</td>\n",
              "      <td>0.06687</td>\n",
              "      <td>6232.81</td>\n",
              "      <td>765.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3146</th>\n",
              "      <th>0</th>\n",
              "      <td>0.19000</td>\n",
              "      <td>0.3880</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>10382.08</td>\n",
              "      <td>1885.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3147</th>\n",
              "      <th>0</th>\n",
              "      <td>0.32000</td>\n",
              "      <td>0.3300</td>\n",
              "      <td>0.13100</td>\n",
              "      <td>0.19000</td>\n",
              "      <td>7936.82</td>\n",
              "      <td>1788.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3148</th>\n",
              "      <th>0</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.8000</td>\n",
              "      <td>0.32000</td>\n",
              "      <td>0.32000</td>\n",
              "      <td>3467.80</td>\n",
              "      <td>2905.58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   close    high      low     open  volumefrom  volumeto\n",
              "date_id coin_id                                                         \n",
              "3144    0        0.06687  0.4444  0.06687  0.06950    39437.24   2994.43\n",
              "3145    0        0.16250  0.1830  0.06687  0.06687     6232.81    765.38\n",
              "3146    0        0.19000  0.3880  0.12500  0.16250    10382.08   1885.11\n",
              "3147    0        0.32000  0.3300  0.13100  0.19000     7936.82   1788.88\n",
              "3148    0        1.00000  1.8000  0.32000  0.32000     3467.80   2905.58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z49gexTJAmXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Google Trends table\n",
        "\n",
        "!pip install pytrends\n",
        "!pip install cryptory\n",
        "import cryptory\n",
        "from cryptory import Cryptory\n",
        "\n",
        "# initialise object \n",
        "# pull data from start of 2017 to present day\n",
        "my_cryptory = Cryptory(from_date = \"2017-01-01\",to_date=\"2019-01-01\", ascending=True)\n",
        "\n",
        "#Pulling google trends data from cryptory \n",
        "\n",
        "i=1\n",
        "google_data_list = []\n",
        "for name in list(df_names['name']):\n",
        "    if(i>0 and i<101):\n",
        "        i=i+1\n",
        "        kw_list = []\n",
        "        kw_list.append(name)\n",
        "        try:\n",
        "            data = my_cryptory.get_google_trends(kw_list)\n",
        "            google_data_list.append(data)\n",
        "        except:\n",
        "            continue;\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "trend_df1 = pd.concat(google_data_list)\n",
        "\n",
        "trend_df2 = pd.DataFrame(trend_df1.pivot_table(index = 'date').unstack()).reset_index()\n",
        "\n",
        "\n",
        "# In[118]:\n",
        "\n",
        "\n",
        "#Adding coin_id column\n",
        "trend_df3 = trend_df2.merge(df_names[['name', 'coin_id']], how = 'left', left_on = 'level_0', right_on = 'name')\n",
        "\n",
        "#Dropping columns\n",
        "trend_df3 = trend_df3.drop(['level_0', 'name'], axis = 1)\n",
        "\n",
        "#Rename columns\n",
        "trend_df3.columns = ['date', 'trend', 'coin_id']\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#Add date_id column\n",
        "trend_df4 = trend_df3.merge(dates_df, how = 'left', left_on = 'date', right_on = 'date').drop('date', axis = 1)\n",
        "\n",
        "\n",
        "# In[394]:\n",
        "\n",
        "\n",
        "trend_df4.set_index(['date_id', 'coin_id'], inplace = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xEMK-pjJctS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# # Twitter Table\n",
        "\n",
        "import re\n",
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "# In[182]:\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "tweets_df = pd.DataFrame({'Date': [], 'No. of Tweets': [], 'Coin': []})\n",
        "\n",
        "for i in range(0,len(df_names['symbol'])-1):\n",
        "    #len(coin_name[\"symbol\"])-1\n",
        "\n",
        "    coin = df_names['symbol'][i]\n",
        "    url = 'https://bitinfocharts.com/comparison/tweets-'+coin.lower()+'.html'\n",
        "    headers = {'User-Agent': \"Chrome/54.0.2840.90\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    html = response.text \n",
        "\n",
        "    from bs4 import BeautifulSoup\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    x = soup.find_all('script')\n",
        "\n",
        "    data_1 = re.findall(r'(\\[new\\sDate.*\\]])', str(x))\n",
        "    data_1 = str(data_1)\n",
        "    \n",
        "    \n",
        "    if data_1 == '[]':\n",
        "        continue\n",
        "    data_2 = data_1.split(\"],[\")\n",
        "    data_2[0] = data_2[0][3:]\n",
        "    data_2[len(data_2) - 1] = data_2[len(data_2) - 1][:-4]\n",
        "    data_pd = pd.DataFrame(data_2)\n",
        "    data_clean = data_pd[0].str.split(\",\", expand = True)\n",
        "    data_clean = data_clean.iloc[:, 0:2]\n",
        "    data_clean.columns = ['Date', 'No. of Tweets']\n",
        "    data_clean[\"Date\"] = data_clean[\"Date\"].str.slice(10,20)\n",
        "    data_clean[\"Coin\"] = coin.upper()\n",
        "    tweets_df = tweets_df.append(data_clean, ignore_index = True)\n",
        "\n",
        "\n",
        "# In[183]:\n",
        "\n",
        "\n",
        "#Convert Date into datetime object\n",
        "tweets_df['Date'] = tweets_df['Date'].astype('datetime64')\n",
        "\n",
        "\n",
        "# In[184]:\n",
        "\n",
        "\n",
        "#Remove the null rows\n",
        "tweets_df = tweets_df[tweets_df['No. of Tweets'] != 'null']\n",
        "\n",
        "\n",
        "# In[185]:\n",
        "\n",
        "\n",
        "#Convert No. of Tweets into int object\n",
        "tweets_df['No. of Tweets'] = tweets_df['No. of Tweets'].astype('int')\n",
        "\n",
        "\n",
        "# In[186]:\n",
        "\n",
        "\n",
        "#Adding coin_id column\n",
        "tweets_df = tweets_df.merge(df_names[['symbol', 'coin_id']], how = 'left', left_on = 'Coin', right_on = 'symbol')\n",
        "\n",
        "#Drop redundant name columns\n",
        "tweets_df = tweets_df.drop(['Coin', 'symbol'], axis = 1)\n",
        "\n",
        "\n",
        "# In[279]:\n",
        "\n",
        "\n",
        "#add date_id column\n",
        "tweets_df2 = tweets_df.merge(dates_df, how = 'left', left_on = 'Date', right_on = 'date')\n",
        "\n",
        "\n",
        "# In[412]:\n",
        "\n",
        "\n",
        "#Change to tweet_count\n",
        "tweets_df2.rename(columns = {'No. of Tweets':'tweet_count'}, inplace = True)\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "tweets_df3 = tweets_df2.drop(['Date', 'date'], axis = 1)\n",
        "\n",
        "\n",
        "# In[414]:\n",
        "\n",
        "\n",
        "tweets_df3.set_index(['date_id', 'coin_id'], inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpmoFpxLi4In",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# # Reddit Subscribers\n",
        "\n",
        "#Subreddits based on symbol\n",
        "\n",
        "empty_df = pd.DataFrame(columns = ['date','total_subscribers','subreddit'])\n",
        "subreddit_list = []\n",
        "for name in list(df_names['symbol']):\n",
        "    try:\n",
        "        subred = my_cryptory.extract_reddit_metrics(subreddit = name, metric = \"total-subscribers\", col_label=\"\", sub_col=True)\n",
        "        if (type(subred) == ValueError):\n",
        "            subreddit_list.append(empty_df)\n",
        "        else:\n",
        "            subreddit_list.append(subred)\n",
        "    except:\n",
        "        subreddit_list.append(empty_df)\n",
        "\n",
        "\n",
        "# In[308]:\n",
        "\n",
        "\n",
        "#Concatenate DF's of symbol-based subreddits\n",
        "reddit_subscribers = pd.concat(subreddit_list)\n",
        "\n",
        "\n",
        "# In[331]:\n",
        "\n",
        "\n",
        "#Add the date_id column\n",
        "reddit_subscribers1 = reddit_subscribers.merge(dates_df, how = 'left', left_on = 'date', right_on = 'date')\n",
        "\n",
        "#Add the coin_id column\n",
        "reddit_subscribers2 = reddit_subscribers1.merge(df_names[['symbol', 'coin_id']], how = 'left', left_on = 'subreddit', right_on = 'symbol')\n",
        "\n",
        "\n",
        "# In[334]:\n",
        "\n",
        "\n",
        "#Drop the symbol column\n",
        "reddit_subscribers3 = reddit_subscribers2.drop(['symbol'], axis = 1)\n",
        "\n",
        "\n",
        "# In[335]:\n",
        "\n",
        "\n",
        "reddit_subscribers3.head()\n",
        "\n",
        "\n",
        "# In[312]:\n",
        "\n",
        "\n",
        "#Subreddits based on name\n",
        "\n",
        "empty_df = pd.DataFrame(columns = ['date','total_subscribers','subreddit'])\n",
        "subreddit_list2 = []\n",
        "for name in list(df_names['name']):\n",
        "    try:\n",
        "        subred = my_cryptory.extract_reddit_metrics(subreddit = name, metric = \"total-subscribers\", col_label=\"\", sub_col=True)\n",
        "        if (type(subred) == ValueError):\n",
        "            subreddit_list2.append(empty_df)\n",
        "        else:\n",
        "            subreddit_list2.append(subred)\n",
        "    except:\n",
        "        subreddit_list2.append(empty_df)\n",
        "\n",
        "\n",
        "# In[314]:\n",
        "\n",
        "\n",
        "#Concatenate DF's of name-based subreddits\n",
        "reddit_subscribers_name = pd.concat(subreddit_list2)\n",
        "\n",
        "\n",
        "# In[336]:\n",
        "\n",
        "\n",
        "#Add the date_id column\n",
        "reddit_subscribers_name1 = reddit_subscribers_name.merge(dates_df, how = 'left', left_on = 'date', right_on = 'date')\n",
        "\n",
        "#Add the coin_id column\n",
        "reddit_subscribers_name2 = reddit_subscribers_name1.merge(df_names[['name', 'coin_id']], how = 'left', left_on = 'subreddit', right_on = 'name')\n",
        "\n",
        "\n",
        "# In[339]:\n",
        "\n",
        "\n",
        "#Drop the name column\n",
        "reddit_subscribers_name3 = reddit_subscribers_name2.drop('name', axis = 1)\n",
        "\n",
        "\n",
        "# In[343]:\n",
        "\n",
        "\n",
        "# CONCATENATE BOTH SUBSCRIBERS TABLES INTO ONE\n",
        "\n",
        "reddit_subscribers_final = pd.concat([reddit_subscribers3, reddit_subscribers_name3])\n",
        "\n",
        "\n",
        "# In[372]:\n",
        "\n",
        "\n",
        "#Drop Redundant date columns\n",
        "reddit_subscribers_final2 = reddit_subscribers_final.drop('date', axis = 1)\n",
        "\n",
        "reddit_subscribers_final2.head()\n",
        "\n",
        "\n",
        "# In[398]:\n",
        "\n",
        "\n",
        "reddit_subscribers_final2.set_index(['date_id', 'coin_id'], inplace = True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haE0pJsaS2qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datalab.context import Context\n",
        "import datalab.storage as gcs\n",
        "context.default().set_project_id('leafy-stock-240814')\n",
        "\n",
        "\n",
        "gcs.Bucket('python_output').item('dates_table_final.csv').write_to(dates_df.to_csv(),'text/csv')\n",
        "\n",
        "gcs.Bucket('python_output').item('reddit_post_final.csv').write_to(reddit_data2.to_csv(encoding='utf-16'),'text/csv')\n",
        "\n",
        "gcs.Bucket('python_output').item('coin_reddit_final.csv').write_to(coin_reddit_join2.to_csv(),'text/csv')\n",
        "\n",
        "gcs.Bucket('python_output').item('google_trends_final.csv').write_to(trend_df4.to_csv(),'text/csv')\n",
        "\n",
        "gcs.Bucket('python_output').item('pricing_final.csv').write_to(pricing_df5.to_csv(),'text/csv')\n",
        "\n",
        "gcs.Bucket('python_output').item('tweets_final.csv').write_to(tweets_df3.to_csv(),'text/csv')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}